{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測蘑菇是否有毒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5079, 99)\n",
      "(565, 99)\n"
     ]
    }
   ],
   "source": [
    "#整理資料\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#整理資料後分別存成train.csv, test.csv\n",
    "def prepare_data(data_file_name):\n",
    "    # http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "    header = ['class', 'cap_shape', 'cap_surface',\n",
    "              'cap_color', 'bruises', 'odor', 'gill_attachment',\n",
    "              'gill_spacing', 'gill_size', 'gill_color', 'stalk_shape',\n",
    "              'stalk_root', 'stalk_surface_above_ring',\n",
    "              'stalk_surface_below_ring', 'stalk_color_above_ring',\n",
    "              'stalk_color_below_ring', 'veil_type', 'veil_color',\n",
    "              'ring_number', 'ring_type', 'spore_print_color',\n",
    "              'population', 'habitat']\n",
    "    df = pd.read_csv(data_file_name, sep=',', names=header)\n",
    "\n",
    "    #移除缺失值\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    #0:有毒，1:可食用\n",
    "    df['class'].replace('p', 0, inplace=True)\n",
    "    df['class'].replace('e', 1, inplace=True)\n",
    "\n",
    "    #類別屬性都拆成one hot\n",
    "    cols_to_transform = header[1:]\n",
    "    df = pd.get_dummies(df, columns=cols_to_transform)                       \n",
    "\n",
    "    #拆成training/test(9:1)\n",
    "    df_train, df_test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "    #5079筆資料\n",
    "    #99個屬性\n",
    "    print (df_train.shape)\n",
    "    print (df_test.shape)    \n",
    "    num_train_entries = df_train.shape[0]                                    \n",
    "    num_train_features = df_train.shape[1] - 1                               \n",
    "\n",
    "    num_test_entries = df_test.shape[0]\n",
    "    num_test_features = df_test.shape[1] - 1\n",
    "    \n",
    "    #分別存成train.csv, test.csv\n",
    "    df_train.to_csv('mushroom_train.csv', index=False)\n",
    "    df_test.to_csv('mushroom_test.csv', index=False)\n",
    "    \n",
    "MUSHROOM_DATA_FILE = \"agaricus-lepiota.data\"\n",
    "prepare_data(MUSHROOM_DATA_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('mushroom_train.csv')\n",
    "train_label = np.array(df_train['class'])\n",
    "train_data =  np.array(df_train.drop('class', axis=1))\n",
    "train_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5079, 98)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('mushroom_test.csv')\n",
    "test_label = np.array(df_test['class'])\n",
    "test_data =  np.array(df_test.drop('class', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#label做one-got encoding\n",
    "def one_hot(values):\n",
    "    n_values = np.max(values) + 1\n",
    "    return np.eye(n_values)[values]\n",
    "train_label = one_hot(train_label.astype(int))\n",
    "test_label = one_hot(test_label.astype(int))\n",
    "\n",
    "print (train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: cross_entropy is 0.6594077348709106\n",
      "step 50: cross_entropy is 0.6101139187812805\n",
      "step 100: cross_entropy is 0.5749460458755493\n",
      "step 150: cross_entropy is 0.4900497496128082\n",
      "step 200: cross_entropy is 0.4006577730178833\n",
      "step 250: cross_entropy is 0.36826613545417786\n",
      "step 300: cross_entropy is 0.35131990909576416\n",
      "step 350: cross_entropy is 0.336247980594635\n",
      "step 400: cross_entropy is 0.25668227672576904\n",
      "step 450: cross_entropy is 0.20671872794628143\n",
      "step 500: cross_entropy is 0.19451303780078888\n",
      "step 550: cross_entropy is 0.17854303121566772\n",
      "step 600: cross_entropy is 0.1629645675420761\n",
      "step 650: cross_entropy is 0.15859925746917725\n",
      "step 700: cross_entropy is 0.12463214248418808\n",
      "step 750: cross_entropy is 0.11447204649448395\n",
      "step 800: cross_entropy is 0.11282957345247269\n",
      "step 850: cross_entropy is 0.08379519730806351\n",
      "step 900: cross_entropy is 0.09613721072673798\n",
      "step 950: cross_entropy is 0.08819933235645294\n",
      "step 1000: cross_entropy is 0.05937248840928078\n",
      "Testing...... accuracy is 0.9876106381416321\n"
     ]
    }
   ],
   "source": [
    "#建DNN，training\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 100\n",
    "INPUT_NODE = 98\n",
    "LAYER1_NODE = 32\n",
    "LAYER2_NODE = 2\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x')\n",
    "y = tf.placeholder(tf.float32, [None, LAYER2_NODE], name='y')\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "b1 = tf.Variable(tf.truncated_normal([LAYER1_NODE], stddev=0.1))\n",
    "W2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, LAYER2_NODE], stddev=0.1))\n",
    "b2 = tf.Variable(tf.truncated_normal([LAYER2_NODE], stddev=0.1))\n",
    "\n",
    "layer_1 = tf.matmul(x, W1) + b1\n",
    "out1 = tf.nn.leaky_relu(layer_1, alpha=0.2)\n",
    "layer_2 = tf.matmul(out1, W2) + b2\n",
    "out2 = tf.nn.leaky_relu(layer_2, alpha=0.2)\n",
    "\n",
    "y_predict = out2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_predict))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"accuracy\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(1001):                                     \n",
    "        i = step\n",
    "        if i+batch_size >= len(train_data):\n",
    "                i = i+batch_size % len(train_data)\n",
    "        batch_xs, batch_ys = train_data[i:i+batch_size], train_label[i:i+batch_size]\n",
    "        \n",
    "        train_step_, cross_entropy_ =sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if step % 50 == 0:\n",
    "            print(\"step {}: cross_entropy is {}\".format(step, cross_entropy_))\n",
    "            \n",
    "    accuracy_ = sess.run(accuracy, feed_dict={x: test_data, y: test_label})\n",
    "    print('Testing...... accuracy is {}'.format(accuracy_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
